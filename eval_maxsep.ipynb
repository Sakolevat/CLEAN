{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from helper.model import *\n",
    "from helper.utils import *\n",
    "from helper.distance_map import *\n",
    "from helper.evaluate import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5242/5242 [03:33<00:00, 24.58it/s] \n"
     ]
    }
   ],
   "source": [
    "args_train_data = \"uniref100_full\"\n",
    "args_test_data = \"price_149\"\n",
    "args_model_name = \"split100_ensemble/split100_5\"  \n",
    " \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "dtype = torch.float32\n",
    "# load id ec from tran and test\n",
    "id_ec_train, ec_id_dict_train = get_ec_id_dict(\n",
    "    './data/' + args_train_data + '.csv')\n",
    "id_ec_test, _ = get_ec_id_dict(\n",
    "    './data/' + args_test_data + '.csv')\n",
    "\n",
    "# load model\n",
    "if False:\n",
    "    # no model used for pretrained embedding\n",
    "    model = lambda *args: args[0]\n",
    "else:\n",
    "    model = LayerNormNet(512, 128, device, dtype)\n",
    "    checkpoint = torch.load('./model/' + args_model_name + '.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "# compute distance map\n",
    "emb_train = model(esm_embedding(ec_id_dict_train, device, dtype))\n",
    "emb_test = model_embedding_test(id_ec_test, model, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding sizes for train and test: torch.Size([241025, 128]) torch.Size([149, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5242/5242 [00:11<00:00, 460.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating eval distance map, between 149 test ids and 5242 train EC cluster centers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [00:00, 1052.10it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_dist = get_dist_map_test(\n",
    "        emb_train, emb_test, ec_id_dict_train, id_ec_test, \n",
    "        device, dtype, dot=False)\n",
    "eval_df = pd.DataFrame.from_dict(eval_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_probs(out_filename, pred_type=\"_maxsep\"):\n",
    "    file_name = out_filename+pred_type\n",
    "    result = open(file_name+'.csv', 'r')\n",
    "    csvreader = csv.reader(result, delimiter=',')\n",
    "    pred_probs = []\n",
    "    for row in csvreader:\n",
    "        preds_ec_lst = []\n",
    "        preds_with_dist = row[1:]\n",
    "        probs = torch.zeros(len(preds_with_dist))\n",
    "        count = 0\n",
    "        \n",
    "        for pred_ec_dist in preds_with_dist:\n",
    "            # get EC number 3.5.2.6 from EC:3.5.2.6/10.8359\n",
    "            ec_i = - float(pred_ec_dist.split(\":\")[1].split(\"/\")[1])\n",
    "            probs[count] = ec_i\n",
    "            #preds_ec_lst.append(probs)\n",
    "            count += 1\n",
    "        # sigmoid of the negative distances \n",
    "        # probs = (1 - torch.exp(-1/probs)) / (1 + torch.exp(-1/probs))\n",
    "        # probs = probs/torch.sum(probs)\n",
    "        probs = torch.nn.functional.softmax(probs)\n",
    "        pred_probs.append(probs)\n",
    "        \n",
    "    return pred_probs\n",
    "\n",
    "\n",
    "def get_pred_dist(out_filename, pred_type=\"_maxsep\"):\n",
    "    file_name = out_filename+pred_type\n",
    "    result = open(file_name+'.csv', 'r')\n",
    "    csvreader = csv.reader(result, delimiter=',')\n",
    "    pred_probs = []\n",
    "    for row in csvreader:\n",
    "        preds_ec_lst = []\n",
    "        preds_with_dist = row[1:]\n",
    "        probs = torch.zeros(len(preds_with_dist))\n",
    "        count = 0\n",
    "        \n",
    "        for pred_ec_dist in preds_with_dist:\n",
    "            # get EC number 3.5.2.6 from EC:3.5.2.6/10.8359\n",
    "            ec_i = float(pred_ec_dist.split(\":\")[1].split(\"/\")[1])\n",
    "            probs[count] = ec_i\n",
    "            #preds_ec_lst.append(probs)\n",
    "            count += 1\n",
    "        # sigmoid of the negative distances \n",
    "       \n",
    "        \n",
    "        pred_probs.append(probs)\n",
    "    return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = './eval/' + args_test_data\n",
    "write_max_sep_choices(eval_df, out_filename, first_grad=True, use_max_grad=False)\n",
    "pred_label = get_pred_labels(out_filename, pred_type='_maxsep')\n",
    "pred_probs= get_pred_probs(out_filename, pred_type='_maxsep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ec_pos_dict(mlb, true_label, pred_label):\n",
    "    ec_list = []\n",
    "    pos_list = []\n",
    "    for i in range(len(true_label)):\n",
    "        ec_list += list(mlb.inverse_transform(mlb.transform([true_label[i]]))[0])\n",
    "        pos_list += list(np.nonzero(mlb.transform([true_label[i]]))[1])\n",
    "    for i in range(len(pred_label)):\n",
    "        ec_list += list(mlb.inverse_transform(mlb.transform([pred_label[i]]))[0])\n",
    "        pos_list += list(np.nonzero(mlb.transform([pred_label[i]]))[1])\n",
    "    label_pos_dict = {}\n",
    "    for i in range(len(ec_list)):\n",
    "        ec, pos = ec_list[i], pos_list[i]\n",
    "        label_pos_dict[ec] = pos\n",
    "        \n",
    "    return label_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ EC calling results using maximum separation ############\n",
      "---------------------------------------------------------------------------\n",
      ">>> total samples: 149 | total ec 56 |\n",
      "precision | recall | F1 | AUC | accuracy\n",
      "0.51864 , 0.44737 , 0.46279 , 0.7234345 , 0.45638\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_dict(eval_dist)\n",
    "# write the top 10 closest EC to _top10.csv\n",
    "out_filename = './eval/' + args_test_data\n",
    "# _ = write_top10_choices(eval_df, out_filename)\n",
    "# maximum separation results\n",
    "write_max_sep_choices(eval_df, out_filename,\n",
    "                        first_grad=True,\n",
    "                        use_max_grad=False)\n",
    "# get preds and true labels\n",
    "pred_label = get_pred_labels(out_filename, pred_type='_maxsep')\n",
    "true_label, all_label = get_true_labels('./data/'+args_test_data)\n",
    "pre, rec, f1, roc, acc = get_eval_metrics(pred_label, true_label, all_label)\n",
    "print(\"############ EC calling results using maximum separation ############\")\n",
    "print('-' * 75)\n",
    "print(f'>>> total samples: {len(true_label)} | total ec {len(all_label)} |\\n'\n",
    "        f'precision | recall | F1 | AUC | accuracy' )\n",
    "print( f'{pre:.5} , {rec:.5} , {f1:.5} , {roc:.7} , {acc:.5}')\n",
    "print('-' * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Maximum separation w correct AUC ############\n",
      "---------------------------------------------------------------------------\n",
      ">>> total samples: 149 | total ec 56 |\n",
      "precision | recall | F1 | AUC | accuracy\n",
      "0.51864 , 0.44737 , 0.46279 , 0.7234575 , 0.45638\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_dict(eval_dist)\n",
    "# write the top 10 closest EC to _top10.csv\n",
    "out_filename = './eval/' + args_test_data\n",
    "# _ = write_top10_choices(eval_df, out_filename)\n",
    "# maximum separation results\n",
    "write_max_sep_choices(eval_df, out_filename, first_grad=True, use_max_grad=False)\n",
    "# get preds and true labels\n",
    "pred_label = get_pred_labels(out_filename, pred_type='_maxsep')\n",
    "pred_probs = get_pred_probs(out_filename, pred_type='_maxsep')\n",
    "true_label, all_label = get_true_labels('./data/'+args_test_data)\n",
    "pre, rec, f1, roc, acc = get_eval_metrics_new(\n",
    "    pred_label, pred_probs, true_label, all_label)\n",
    "print(\"############ Maximum separation w correct AUC ############\")\n",
    "print('-' * 75)\n",
    "print(f'>>> total samples: {len(true_label)} | total ec {len(all_label)} |\\n'\n",
    "        f'precision | recall | F1 | AUC | accuracy' )\n",
    "print( f'{pre:.5} , {rec:.5} , {f1:.5} , {roc:.7} , {acc:.5}')\n",
    "print('-' * 75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "386218770bb7053658aedbdb94aaaba888065d92b04918111f39a883f4943438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
