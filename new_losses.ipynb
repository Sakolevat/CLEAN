{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from helper.dataloader import *\n",
    "from helper.model import *\n",
    "from helper.utils import *\n",
    "from helper.losses import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from helper.distance_map import get_dist_map\n",
    "dtype = torch.float32\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple postive multiple negative dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-pair loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 6.433290481567383\n",
      "the grad of fc1 layer is: tensor([[-4.8914e-03, -2.0231e-03,  4.1318e-03,  ..., -1.6695e-03,\n",
      "          1.7229e-03, -2.7476e-03],\n",
      "        [ 1.0904e-02, -1.3277e-02, -3.2206e-03,  ..., -1.7161e-03,\n",
      "         -2.7405e-03, -7.5002e-03],\n",
      "        [-3.0050e-03, -6.1143e-03, -3.8868e-03,  ...,  1.4125e-03,\n",
      "          7.5213e-03,  6.8182e-03],\n",
      "        ...,\n",
      "        [ 4.4915e-03,  7.5347e-03, -3.2780e-03,  ...,  4.0461e-05,\n",
      "          3.3811e-03, -7.3777e-03],\n",
      "        [ 4.0005e-03, -3.6585e-03, -3.7010e-03,  ..., -8.1621e-03,\n",
      "         -5.8130e-04, -1.2024e-03],\n",
      "        [-3.7205e-03, -1.0952e-03, -5.4550e-03,  ..., -4.0717e-04,\n",
      "          3.1118e-04,  9.3065e-03]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "args_hidden_dim = 512\n",
    "args_out_dim = 128\n",
    "model = LayerNormNet(args_hidden_dim, args_out_dim, device, dtype)\n",
    "checkpoint = torch.load('./model/uniref10_split1_final.pth')\n",
    "model.zero_grad()\n",
    "# the input to the model will be of size [bsz, (1+n_pos+n_neg), 1280]\n",
    "n_pos = 1; n_neg = 30; bsz = 400; temp = 0.1\n",
    "n_all = 1 + n_pos + n_neg\n",
    "dummy_input = torch.randn(bsz, n_all, 1280).to(device, dtype)\n",
    "model_emb = model(dummy_input)\n",
    "loss = NPairLoss(model_emb, temp)\n",
    "loss.backward()\n",
    "print(\"loss is:\", loss.item())\n",
    "print(\"the grad of fc1 layer is:\", model.fc1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SupCon Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is: 6.3981146812438965\n",
      "the grad of fc1 layer is: tensor([[-0.0002,  0.0006, -0.0036,  ..., -0.0042,  0.0003,  0.0011],\n",
      "        [ 0.0089, -0.0080,  0.0055,  ..., -0.0009,  0.0020,  0.0026],\n",
      "        [ 0.0008, -0.0011,  0.0004,  ...,  0.0025,  0.0010,  0.0015],\n",
      "        ...,\n",
      "        [ 0.0014, -0.0014,  0.0008,  ..., -0.0012, -0.0020, -0.0017],\n",
      "        [-0.0009,  0.0002, -0.0023,  ..., -0.0014,  0.0006, -0.0015],\n",
      "        [-0.0046,  0.0005,  0.0002,  ..., -0.0016, -0.0012, -0.0003]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "args_hidden_dim = 512\n",
    "args_out_dim = 128\n",
    "model = LayerNormNet(args_hidden_dim, args_out_dim, device, dtype)\n",
    "checkpoint = torch.load('./model/uniref10_split1_final.pth')\n",
    "model.zero_grad()\n",
    "# the input to the model will be of size [bsz, (1+n_pos+n_neg), 1280]\n",
    "n_pos = 10; n_neg = 30; bsz = 400; temp = 0.1\n",
    "n_all = 1 + n_pos + n_neg\n",
    "dummy_input = torch.randn(bsz, n_all, 1280).to(device, dtype)\n",
    "model_emb = model(dummy_input)\n",
    "loss = SupConHardLoss(model_emb, temp, n_pos)\n",
    "loss.backward()\n",
    "print(\"loss is:\", loss.item())\n",
    "print(\"the grad of fc1 layer is:\", model.fc1.weight.grad)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "386218770bb7053658aedbdb94aaaba888065d92b04918111f39a883f4943438"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
